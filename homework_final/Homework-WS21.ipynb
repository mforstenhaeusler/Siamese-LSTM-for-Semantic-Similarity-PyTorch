{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework (Mini-project)\n",
    "\n",
    "Objective of this assignment is to implement the basic building blocks of a Deep Learning pipeline on a sample supervised-learning problem in **PyTorch**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Name: Maximilian Forstenhaeusler\n",
    "\n",
    "Matriculation No.: 03744460\n",
    "\n",
    "**Important:** Do not forget to fill the places where you see `### Your code goes here ###`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task and Setup\n",
    "\n",
    "In this assignment, we want you to experience doing a mini-project in PyTorch. You are supposed to build the different parts of the pipeline as illustrated in the course notebooks (DataLoading, Model, Loss, Training, Evaluation). For this purpose, we will use a dataset from Quora containing question pairs and labels whether the pair is a duplicate or not.\n",
    "\n",
    "The data can be found in Moodle in a csv file. The data is This data is subject to Quora's [Terms of Service](https://www.quora.com/about/tos), allowing for non-commercial use. The dataset was downloaded from https://www.kaggle.com/quora/question-pairs-dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Classifiying Duplicate Question Pairs** \n",
    "\n",
    "\n",
    "We want to build a DL Model that can predict whether two questions from a Quora dataset are duplicates or not. Note that the two questions must not be identical as you will see in the dataset, rather they semantically mean almost the same thing.\n",
    "\n",
    "To make the setup a bit simpler, we extracted and prepared a small subset of the original data consisting of 50k examples. Additionally, we removed questions that are too long or too short, we kept questions of length between 30 and 50 characters. Those 50k examples should serve as training and validation data, please consider making a reasonable split. Do not train on the validation data, just use it to evaluate your model.\n",
    "\n",
    "**Model Inputs and Label**:\n",
    "\n",
    "Input Format: 2 questions, for each question you will have an input of `BATCH_SIZE X SEQ_LEN`, where SEQ_LEN is the number of tokens in the question. Of course, if you will stack the input into batches, you will need to pad the questions (i.e. add a padding token or zeros at the end of the question to make all questions equal in length).\n",
    "\n",
    "Label Format: `BATCH_SIZE X 1`, please note that the extra dimension (`X 1`) is optional and dependent on your implementaiton, you could have a simple 1D tensor of length `BATCH_SIZE`, where each value is either 0 or 1 indicating that the two questions are either non-duplicates or not, respectively.\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "1. Please read the csv file and explore the dataset a bit in order to familize yourself with the problem before working on it.\n",
    "\n",
    "2. In your custom DataLoader you have to make sure that you provide two questions for each example, this should be done in the `def __getitem__(self, idx)` method.\n",
    "\n",
    "3. Please work at the word-level, your tokens are words. You will need to preprocess the data accordingly. Feel free to write simple Python code that can do the job, but also consider using tokenizers, stemmers, and lemmatizers from known NLP libraries such as [NLTK](https://www.nltk.org/) or [SpaCy](https://spacy.io/).\n",
    "\n",
    "4. You will need to encode the words into integers to be able to pass them to the model, you will also need to keep track of the vocabulary. For this purpose, you can also write your own Python code or use an out-of-the-box module such as `torchtext.data.vocab` (see example in the data loading notebook). You can include this part in your Dataset class if you like.\n",
    "\n",
    "5. You will most probalby need to use an embedding layer as input to the model, it will then take the sequence of integers and return numeric vectors representing each word. Please consider using pre-trained embeddings, there are multiple ways how to load these into your newly-created Embedding layer, `torchtext` also provides some easy ways to do that.\n",
    "\n",
    "6. With Embeddings, you will have two options:\n",
    "    - train your own embeddings on the task, either by starting from random weights or after loading pre-trained embeddings (this will take more time and probably need Colab or GPU)\n",
    "    - or freeze the pre-trained embeddings and train the rest of the network (make sure the embedding layer is frozen, `requires_grad` is set to `False`.\n",
    "\n",
    "7. Note that you will need to encode the questions as integers based on the vocabulary you are using. This sequence of integers will be fed as input to the model (embeddings lookup, then the following layers).\n",
    "\n",
    "8. Take care that the model have two inputs (two sentences in parallel). This should be done in your implementation of the `def forward(self, question1, qustion2)` in your custom model class.\n",
    "\n",
    "9. Since you need to feed both question to your model, in the `forward` you will have to let each question go through a couple of layers to get a representation for each question. Then, you will have to combine the two representations in any way you see possible (e.g. multiply them, subtract them, concatenate them). Finally, with this final representation, you will have to let it go through a couple of layers (mostly fully-connected layers) and then predict the outcome (2 classes).\n",
    "\n",
    "10. This is generally a binary classification problem, you can use a classification loss to train your model. There are more advanced loss functions that are related to Siamese Networks (which is this architecture since it has multiple parallel inputs), feel free to use or explore them.\n",
    "\n",
    "11. A nice lecture about the topic is here: Siamese Networks and Similarity Learning Lecture, Prof. Dr. Laura Leal-Taix√©, Advanced Deep Learning for Computer Vision Course:https://www.youtube.com/watch?v=6e65XfwmIWE\n",
    "\n",
    "12. Good summary and course notes of Deep Learning specialization on Coursera: https://github.com/mbadry1/DeepLearning.ai-Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction (Comments for running)\n",
    "\n",
    "I implemented a Siamese LSTM Network to solve this task using pre-trained embedded weights. I used the `GoogleNews-vectors-negative300.bin` embeddings to create the pre-trained embedded weights. <br><br>\n",
    "Because the Google Embeddings are soo large (3 billion entries I think), I created a weight tensor and stored it, `pretrained_weight.pt`. Instead of recreating a new weight tensor each time this notebook is run, as the vocabulary does not change, I load the stored pre-trained weigths tensor. The function how the pre-trained weights tensor is created can be found in `.model.utils.py.`<br>\n",
    "\n",
    "Please keep the variable, `log_to_wandb = False` (hparams) when you are running this notebook in google collab. The runtime on cpu for 50 epochs is about 20 minutes.  \n",
    "\n",
    "Please adjust the file path (`DATASET_FILE_PATH`) to where your data file is stored.\n",
    "\n",
    "You can access the my wandb dashboard here: https://wandb.ai/maxifor/IBM-Praktikum%20Homework%202?workspace=user-maxifor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homework_code.dataset.quora_dataset import QuoraDataset, collate\n",
    "from homework_code.dataset.utils import convert_data_to_tuples, text_to_wordlist\n",
    "from homework_code.dataset.language import Language\n",
    "from homework_code.model.network import EmbeddingLSTMNet, SiameseNetwork\n",
    "from homework_code.model.model_trainer import ModelTrainer\n",
    "from homework_code.model.utils import create_pretrained_weights, plotConfusionMatrix, save_model\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global varibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root and directory paths \n",
    "ROOT_PATH = os.getcwd()\n",
    "DATA_FOLDER_PATH = ROOT_PATH + '/data'\n",
    "GOOGLE_EMBEDDING_FOLDER_PATH = DATA_FOLDER_PATH + '/google embedding'\n",
    "GOOGLE_EMBEDDING = GOOGLE_EMBEDDING_FOLDER_PATH + '/GoogleNews-vectors-negative300.bin'\n",
    "MODEL_FOLDER_PATH = ROOT_PATH \n",
    "# important paths \n",
    "DATASET_FILE_PATH = DATA_FOLDER_PATH + '/mini_quora_dataset_30_50_50k.csv'\n",
    "EMBEDDING_PATH = GOOGLE_EMBEDDING_FOLDER_PATH + GOOGLE_EMBEDDING\n",
    "\n",
    "# general variables\n",
    "EMBEDDING_REQUIRES_GRAD = False\n",
    "NUM_LAYERS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperperameters \n",
    "\n",
    "hparams = {\n",
    "    'threshold': torch.Tensor([0.5]),\n",
    "    'learning_rate': 1e-03,\n",
    "    'epoch': 50,\n",
    "    'batch_size': 32,\n",
    "    'hidden_dim': 100,\n",
    "    'embedding_dim': 300,\n",
    "    'dropout': 0.0,\n",
    "    'remove_stopwords': False,\n",
    "    'stem_words': False,\n",
    "    'simple': True,\n",
    "    'log_to_wandb': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data Loading (30 Points)\n",
    "\n",
    "1. Write code to read the dataset after you download it from Moodle.\n",
    "2. Explore some examples and check if you need to do some data cleaning or remove some bad examples.\n",
    "3. Decide on what preprocessing steps you will do to the text of the questions.\n",
    "4. Build a custom PyTorch dataset where you implement the required methods `__getitem__` and `__len__`. Do not forget to integrate any preprocessing steps in the class. Make sure that you also have a function that applies the whole preprocessing to a raw example, this will be very helpful when you want to predict for test examples later.\n",
    "5. Split the data into train and validation data. Use a reasonable split ratio.\n",
    "6. Create PyTorch dataloaders for train and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code goes here ####\n",
    "# all my code is in a seperate python package (homework_code) attached to the submission "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>max_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>307549</td>\n",
       "      <td>603786</td>\n",
       "      <td>603787</td>\n",
       "      <td>What are some different ways to make money fast?</td>\n",
       "      <td>What are fast ways to make money?</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>221916</td>\n",
       "      <td>437426</td>\n",
       "      <td>437427</td>\n",
       "      <td>How can I continue to improve my English?</td>\n",
       "      <td>How can I understand english?</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>177830</td>\n",
       "      <td>351280</td>\n",
       "      <td>351281</td>\n",
       "      <td>How do I promote my youtube videos?</td>\n",
       "      <td>What is the best way to promote YouTube videos?</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>128018</td>\n",
       "      <td>253605</td>\n",
       "      <td>253606</td>\n",
       "      <td>How can I organize a Quora Meetup in Pune?</td>\n",
       "      <td>Is there a Pune Quora Meetup group?</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>177761</td>\n",
       "      <td>351144</td>\n",
       "      <td>351145</td>\n",
       "      <td>What is the most badass moment of Game of Thro...</td>\n",
       "      <td>Who will die in season 5 of Game of Thrones?</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49995</td>\n",
       "      <td>95213</td>\n",
       "      <td>189005</td>\n",
       "      <td>189006</td>\n",
       "      <td>How does drop shipping work exactly?</td>\n",
       "      <td>What is drop shipping and how does it work?</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49996</td>\n",
       "      <td>62682</td>\n",
       "      <td>124658</td>\n",
       "      <td>124659</td>\n",
       "      <td>What are the best movies to watch in Hollywood?</td>\n",
       "      <td>Which are the best Hollywood movies of all time?</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49997</td>\n",
       "      <td>109939</td>\n",
       "      <td>218008</td>\n",
       "      <td>218009</td>\n",
       "      <td>Am I a sociopath, schizoid, or neither?</td>\n",
       "      <td>Am I a sociopath?</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49998</td>\n",
       "      <td>370854</td>\n",
       "      <td>725712</td>\n",
       "      <td>725713</td>\n",
       "      <td>What is your marketing strategy?</td>\n",
       "      <td>What is a market strategy?</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49999</td>\n",
       "      <td>268327</td>\n",
       "      <td>527813</td>\n",
       "      <td>527814</td>\n",
       "      <td>What will be the qualifying marks for neet 2016?</td>\n",
       "      <td>What might be the qualifing mark in neet 2016?</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    qid1    qid2  \\\n",
       "0      307549  603786  603787   \n",
       "1      221916  437426  437427   \n",
       "2      177830  351280  351281   \n",
       "3      128018  253605  253606   \n",
       "4      177761  351144  351145   \n",
       "...       ...     ...     ...   \n",
       "49995   95213  189005  189006   \n",
       "49996   62682  124658  124659   \n",
       "49997  109939  218008  218009   \n",
       "49998  370854  725712  725713   \n",
       "49999  268327  527813  527814   \n",
       "\n",
       "                                               question1  \\\n",
       "0       What are some different ways to make money fast?   \n",
       "1              How can I continue to improve my English?   \n",
       "2                    How do I promote my youtube videos?   \n",
       "3             How can I organize a Quora Meetup in Pune?   \n",
       "4      What is the most badass moment of Game of Thro...   \n",
       "...                                                  ...   \n",
       "49995               How does drop shipping work exactly?   \n",
       "49996    What are the best movies to watch in Hollywood?   \n",
       "49997            Am I a sociopath, schizoid, or neither?   \n",
       "49998                   What is your marketing strategy?   \n",
       "49999   What will be the qualifying marks for neet 2016?   \n",
       "\n",
       "                                              question2  is_duplicate  \\\n",
       "0                     What are fast ways to make money?             1   \n",
       "1                         How can I understand english?             1   \n",
       "2       What is the best way to promote YouTube videos?             1   \n",
       "3                   Is there a Pune Quora Meetup group?             0   \n",
       "4          Who will die in season 5 of Game of Thrones?             0   \n",
       "...                                                 ...           ...   \n",
       "49995       What is drop shipping and how does it work?             1   \n",
       "49996  Which are the best Hollywood movies of all time?             1   \n",
       "49997                                 Am I a sociopath?             0   \n",
       "49998                        What is a market strategy?             0   \n",
       "49999    What might be the qualifing mark in neet 2016?             1   \n",
       "\n",
       "       max_length  \n",
       "0              48  \n",
       "1              41  \n",
       "2              47  \n",
       "3              42  \n",
       "4              50  \n",
       "...           ...  \n",
       "49995          43  \n",
       "49996          48  \n",
       "49997          39  \n",
       "49998          32  \n",
       "49999          48  \n",
       "\n",
       "[50000 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_FILE_PATH)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Pairs:  49999\n"
     ]
    }
   ],
   "source": [
    "# select question pairs and labels\n",
    "q_pair, labels = convert_data_to_tuples(df, hparams['remove_stopwords'], hparams['stem_words'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = Language()\n",
    "for data in [q_pair]:\n",
    "    for question_pair in data:\n",
    "        q1 = question_pair[0]\n",
    "        q2 = question_pair[1]\n",
    "        language.addSentence(q1)\n",
    "        language.addSentence(q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_dataset = QuoraDataset(q_pair, language.word2index, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question 1: what are some different ways to make money fast\n",
      "question 2: what are fast ways to make money\n",
      "tokens  q1: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "tokens  q2: [1, 2, 9, 5, 6, 7, 8]\n",
      "labels    : 1\n"
     ]
    }
   ],
   "source": [
    "# example \n",
    "for sample in quora_dataset:\n",
    "    print('question 1:', sample['q1'])\n",
    "    print('question 2:', sample['q2'])\n",
    "    print('tokens  q1:', sample['q1_token'])\n",
    "    print('tokens  q2:', sample['q2_token'])\n",
    "    print('labels    :', sample['labels'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size 39999, Validation Set Size 10000,\n"
     ]
    }
   ],
   "source": [
    "train_split = 0.8\n",
    "val_split = 0.2\n",
    "\n",
    "dataset_size = len(quora_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "\n",
    "split_train = int(train_split*dataset_size)\n",
    "\n",
    "shuffle_dataset = True\n",
    "random_seed = 46\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[:split_train], indices[split_train:]\n",
    "\n",
    "assert len(train_indices) + len(val_indices) == dataset_size\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "#test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(quora_dataset, batch_size=hparams['batch_size'], sampler=train_sampler, collate_fn=collate)\n",
    "val_dataloader = torch.utils.data.DataLoader(quora_dataset, batch_size=hparams['batch_size'], sampler=val_sampler, collate_fn=collate)\n",
    "#test_dataloader = torch.utils.data.DataLoader(quora_dataset, batch_size=hparams['batch_size'], sampler=test_sampler, collate_fn=collate)\n",
    "\n",
    "#test_predict_dataloader = torch.utils.data.DataLoader(quora_dataset, batch_size=1, sampler=test_sampler, collate_fn=collate)\n",
    "\n",
    "print('Training Set Size {}, Validation Set Size {},'.format(len(train_indices), len(val_indices)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Model (20 Points)\n",
    "\n",
    "1. Explore what possible models for the task could be. You do not need to come up with a very complex model, a relatively small model consisting of the following sequence would be okay: {*Embeddings for the input - LSTM or CNN to process the sequence - Linear Layers to learn features from the combined representation of the questions - Output Layer*} would also be fine, just take care of the sizing of the different layers. Please always check the sizing after each layer and make sure you understand the dimensions correclty and they map to what you have in mind.\n",
    "2. Build a model class.\n",
    "3. Test your model with one batch from your dataloader and check the input and output shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code goes here ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pretrained weights \n",
    "# skip this step because time consuming and might make cpu brake\n",
    "# instead import the pretrained_weights.pt (see additional comments in at the top)\n",
    "\n",
    "# pretrained_weights = create_pretrained_weights(GOOGLE_EMBEDDING, EMBEDDING_DIMENSION, language)\n",
    "# pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1396, -0.0062,  0.2148,  ...,  0.0571,  0.0996, -0.2344],\n",
       "        [-0.0967, -0.0264,  0.0903,  ..., -0.0197,  0.2139,  0.1367],\n",
       "        ...,\n",
       "        [-0.2100, -0.3711, -0.1211,  ..., -0.0066,  0.0742, -0.0233],\n",
       "        [-0.1348, -0.0233, -0.0640,  ...,  0.2051,  0.1226, -0.1250],\n",
       "        [-0.0381, -0.1445,  0.1426,  ...,  0.0216,  0.0688,  0.0171]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_weights = torch.load('pretrained_weights.pt')\n",
    "pretrained_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding net\n",
    "embedding_net = EmbeddingLSTMNet(\n",
    "    hparams['embedding_dim'],\n",
    "    hparams['hidden_dim'],\n",
    "    NUM_LAYERS,\n",
    "    EMBEDDING_REQUIRES_GRAD,\n",
    "    pretrained_weights,\n",
    "    hparams['dropout'],\n",
    "    hparams['simple'], # if simple=True --> simple model, if simple=False --> more complex model (2 linear layers plus relu)\n",
    ")\n",
    "\n",
    "# siamese model\n",
    "model = SiameseNetwork(embedding_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2463e-01, 2.9048e-01, 7.3643e-01, 4.9852e-02, 2.2811e-04, 2.4283e-02,\n",
       "        4.4411e-03, 3.1908e-05, 1.7725e-03, 1.9039e-01, 1.7178e-04, 8.3238e-03,\n",
       "        1.1665e-01, 1.3213e-02, 1.0374e-01, 2.7834e-04, 2.9381e-04, 8.5191e-07,\n",
       "        3.6771e-03, 3.0912e-01, 4.0798e-02, 3.1815e-01, 7.6843e-03, 2.5006e-02,\n",
       "        1.8881e-02, 6.0260e-03, 5.7669e-04, 1.5585e-06, 4.8929e-02, 1.1621e-04,\n",
       "        8.2544e-01], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model class with one batch from the dataloader \n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    q1, q2 = batch['q1_token'], batch['q2_token']\n",
    "    q1_len, q2_len = batch['q1_lengths'], batch['q2_lengths']\n",
    "    y = torch.FloatTensor(batch['labels'])\n",
    "\n",
    "model(q1, q2, q1_len, q2_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Training (30 Points)\n",
    "\n",
    "1. Develop Training and Validation code.\n",
    "2. Choose a suitable loss function.\n",
    "3. Refactor the code so that it can be easily modified and adapted (use methods, classes, etc...)\n",
    "4. Make sure to save your trained model when you reach a good score on the validation dataset.\n",
    "5. Plot the training and validation losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code goes here ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Maxi/opt/anaconda3/lib/python3.7/site-packages/cryptography/hazmat/backends/openssl/x509.py:18: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  utils.DeprecatedIn35,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaxifor\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/maxifor/IBM-Praktikum%20Homework%202/runs/2sk92p8m\" target=\"_blank\">earthy-smoke-15</a></strong> to <a href=\"https://wandb.ai/maxifor/IBM-Praktikum%20Homework%202\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = ModelTrainer(\n",
    "    model, \n",
    "    hparams, \n",
    "    train_dataloader, \n",
    "    val_dataloader,\n",
    "    train_indices, \n",
    "    val_indices,\n",
    "    log_to_wandb=hparams['log_to_wandb'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:36<00:00, 33.85batch/s, train_acc=78.125 %, train_loss=0.213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Validation: val_loss: 0.18973050614039358 val_acc: 72.43 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:36<00:00, 34.55batch/s, train_acc=81.25 %, train_loss=0.177] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Validation: val_loss: 0.17838695128790485 val_acc: 74.32 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:37<00:00, 33.57batch/s, train_acc=84.375 %, train_loss=0.165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Validation: val_loss: 0.17314270100654505 val_acc: 75.26 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:39<00:00, 31.82batch/s, train_acc=81.25 %, train_loss=0.158] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Validation: val_loss: 0.16942250788116608 val_acc: 76.27000000000001 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:37<00:00, 33.21batch/s, train_acc=78.125 %, train_loss=0.152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Validation: val_loss: 0.16775591381060811 val_acc: 76.16000000000001 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:37<00:00, 33.74batch/s, train_acc=75.0 %, train_loss=0.148]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Validation: val_loss: 0.16556823877290414 val_acc: 76.81 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:35<00:00, 35.13batch/s, train_acc=81.25 %, train_loss=0.144] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Validation: val_loss: 0.1646968228653216 val_acc: 76.91 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:36<00:00, 34.67batch/s, train_acc=71.875 %, train_loss=0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Validation: val_loss: 0.1634433264025865 val_acc: 77.25 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:37<00:00, 33.75batch/s, train_acc=81.25 %, train_loss=0.138] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Validation: val_loss: 0.1627861496549064 val_acc: 77.57 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:36<00:00, 34.51batch/s, train_acc=81.25 %, train_loss=0.136] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Validation: val_loss: 0.1622017966910673 val_acc: 77.44 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:36<00:00, 34.00batch/s, train_acc=78.125 %, train_loss=0.134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] Validation: val_loss: 0.16137812308038765 val_acc: 77.55 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:36<00:00, 33.79batch/s, train_acc=81.25 %, train_loss=0.132] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] Validation: val_loss: 0.1609351500487937 val_acc: 77.41 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:35<00:00, 34.83batch/s, train_acc=84.375 %, train_loss=0.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] Validation: val_loss: 0.1605716118464074 val_acc: 77.48 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:35<00:00, 35.00batch/s, train_acc=75.0 %, train_loss=0.129]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] Validation: val_loss: 0.16009698558253602 val_acc: 77.53 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:38<00:00, 32.22batch/s, train_acc=78.125 %, train_loss=0.127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] Validation: val_loss: 0.16023091307749002 val_acc: 77.49000000000001 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:38<00:00, 32.69batch/s, train_acc=87.5 %, train_loss=0.126]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] Validation: val_loss: 0.15983685905845782 val_acc: 77.61 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:33<00:00, 36.98batch/s, train_acc=78.125 %, train_loss=0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] Validation: val_loss: 0.15980664126503583 val_acc: 77.63 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:38<00:00, 32.67batch/s, train_acc=78.125 %, train_loss=0.124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50] Validation: val_loss: 0.1593613652423167 val_acc: 77.64 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:41<00:00, 29.89batch/s, train_acc=84.375 %, train_loss=0.123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50] Validation: val_loss: 0.15893635018088947 val_acc: 77.66 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:39<00:00, 31.50batch/s, train_acc=78.125 %, train_loss=0.122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50] Validation: val_loss: 0.15898267798625623 val_acc: 77.73 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:39<00:00, 31.30batch/s, train_acc=81.25 %, train_loss=0.121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50] Validation: val_loss: 0.15920295959082656 val_acc: 77.74 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:35<00:00, 35.11batch/s, train_acc=81.25 %, train_loss=0.121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50] Validation: val_loss: 0.1586328907944143 val_acc: 77.7 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:37<00:00, 33.75batch/s, train_acc=84.375 %, train_loss=0.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50] Validation: val_loss: 0.15853497669243585 val_acc: 77.8 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:36<00:00, 34.40batch/s, train_acc=81.25 %, train_loss=0.12] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50] Validation: val_loss: 0.15856002609188946 val_acc: 77.66999999999999 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:35<00:00, 34.97batch/s, train_acc=84.375 %, train_loss=0.119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50] Validation: val_loss: 0.1584977205045307 val_acc: 77.75999999999999 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:36<00:00, 34.54batch/s, train_acc=87.5 %, train_loss=0.119] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50] Validation: val_loss: 0.15823650424377605 val_acc: 77.84 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:37<00:00, 33.26batch/s, train_acc=87.5 %, train_loss=0.118]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50] Validation: val_loss: 0.15885921291554697 val_acc: 77.79 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:35<00:00, 35.63batch/s, train_acc=93.75 %, train_loss=0.118] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50] Validation: val_loss: 0.15836900839219079 val_acc: 77.75 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:37<00:00, 33.36batch/s, train_acc=96.875 %, train_loss=0.118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50] Validation: val_loss: 0.15851700460663237 val_acc: 77.8 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [30/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:36<00:00, 34.15batch/s, train_acc=84.375 %, train_loss=0.117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50] Validation: val_loss: 0.158527193763576 val_acc: 77.7 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [31/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:36<00:00, 33.90batch/s, train_acc=81.25 %, train_loss=0.117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50] Validation: val_loss: 0.15831023499893304 val_acc: 77.86 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [32/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:35<00:00, 35.51batch/s, train_acc=87.5 %, train_loss=0.117]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50] Validation: val_loss: 0.1582283236967108 val_acc: 77.84 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [33/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:38<00:00, 32.07batch/s, train_acc=81.25 %, train_loss=0.117] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50] Validation: val_loss: 0.15821933643981673 val_acc: 77.75999999999999 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [34/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:33<00:00, 37.82batch/s, train_acc=81.25 %, train_loss=0.116] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50] Validation: val_loss: 0.15823161785309306 val_acc: 77.81 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [35/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:34<00:00, 36.51batch/s, train_acc=93.75 %, train_loss=0.116] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50] Validation: val_loss: 0.15808086685193612 val_acc: 77.8 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [36/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:32<00:00, 38.08batch/s, train_acc=93.75 %, train_loss=0.116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50] Validation: val_loss: 0.15823743516168656 val_acc: 77.78 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [37/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:37<00:00, 33.73batch/s, train_acc=87.5 %, train_loss=0.116] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50] Validation: val_loss: 0.15821202365925519 val_acc: 77.79 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [38/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:36<00:00, 34.65batch/s, train_acc=90.625 %, train_loss=0.115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50] Validation: val_loss: 0.1582144344814669 val_acc: 77.82 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [39/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:35<00:00, 34.73batch/s, train_acc=87.5 %, train_loss=0.115]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50] Validation: val_loss: 0.15820031520276787 val_acc: 77.8 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [40/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:37<00:00, 33.33batch/s, train_acc=90.625 %, train_loss=0.116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50] Validation: val_loss: 0.15815879334323704 val_acc: 77.81 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [41/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:35<00:00, 34.84batch/s, train_acc=90.625 %, train_loss=0.115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50] Validation: val_loss: 0.15809458879807506 val_acc: 77.82 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [42/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:33<00:00, 36.96batch/s, train_acc=87.5 %, train_loss=0.115]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50] Validation: val_loss: 0.1581059260109362 val_acc: 77.81 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [43/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:34<00:00, 36.48batch/s, train_acc=87.5 %, train_loss=0.115] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50] Validation: val_loss: 0.15815967468979258 val_acc: 77.86999999999999 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [44/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:33<00:00, 37.29batch/s, train_acc=90.625 %, train_loss=0.115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50] Validation: val_loss: 0.15815931132521494 val_acc: 77.84 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [45/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:33<00:00, 37.27batch/s, train_acc=96.875 %, train_loss=0.115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50] Validation: val_loss: 0.15831434526763405 val_acc: 77.85 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [46/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:33<00:00, 37.32batch/s, train_acc=87.5 %, train_loss=0.115]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50] Validation: val_loss: 0.1581031244736129 val_acc: 77.85 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [47/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:35<00:00, 35.62batch/s, train_acc=87.5 %, train_loss=0.115]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50] Validation: val_loss: 0.157959501511944 val_acc: 77.81 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [48/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:36<00:00, 34.18batch/s, train_acc=93.75 %, train_loss=0.115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50] Validation: val_loss: 0.1580343808467015 val_acc: 77.82 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [49/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:35<00:00, 35.16batch/s, train_acc=90.625 %, train_loss=0.115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50] Validation: val_loss: 0.15793543075696348 val_acc: 77.84 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [50/50]  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:36<00:00, 34.01batch/s, train_acc=90.625 %, train_loss=0.115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50] Validation: val_loss: 0.15808526662211067 val_acc: 77.85 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 16108... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train_loss</td><td>‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_acc</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_loss</td><td>‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>87.24468</td></tr><tr><td>train_loss</td><td>0.11482</td></tr><tr><td>val_acc</td><td>77.85</td></tr><tr><td>val_loss</td><td>0.15809</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">earthy-smoke-15</strong>: <a href=\"https://wandb.ai/maxifor/IBM-Praktikum%20Homework%202/runs/2sk92p8m\" target=\"_blank\">https://wandb.ai/maxifor/IBM-Praktikum%20Homework%202/runs/2sk92p8m</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211108_230812-2sk92p8m/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you like to store the model, uncomment the following lines and enter filename and path \n",
    "\n",
    "filename = \"model.pt\"\n",
    "path = ROOT_PATH\n",
    "save_model(model, path + \"/\" + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the training and validation plots in wandb: https://wandb.ai/maxifor/IBM-Praktikum%20Homework%202?workspace=user-maxifor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Evaluation (20 Points)\n",
    "\n",
    "1. Report some suitable evaluation metrics. If you stick to standard classification, please report the classification metrics we discussed in the evaluation notebook.\n",
    "2. Check some example and results from the training data.\n",
    "3. Check some examples and results from the validation data (not used for training).\n",
    "4. Come up with one pair of questions and see if your model can produce a reasonable prediction for them. For this, you need to apply the preprocessing pipeline and encoding on the questions' text and make inference to see if the model predicts that they are duplicates.\n",
    "5. Conclude with some comments\n",
    "6. Give us your feedback about the task (at least a sentence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code goes here ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - Model Performance - - -\n",
      "\n",
      "Model Accuracy:  77.85\n",
      "Correct predictions: 7785, Incorret predictions: 2215\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 4193\n",
      "FP: 923\n",
      "FN: 1292\n",
      "TN: 3592\n",
      "\n",
      "Percision Score: 0.7354627354627354\n",
      "Recall Score: 0.7955703211517166\n",
      "F1 Score: 0.7643366315565485\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments on evaluation metrics\n",
    "\n",
    "##### Best Result\n",
    "- The best results were achieved with a the following hyperparameters:\n",
    "    - hparams = {\n",
    "            'threshold': torch.Tensor([0.5]),\n",
    "            'learning_rate': 1e-03,\n",
    "            'epoch': 50,\n",
    "            'batch_size': 32,\n",
    "            'hidden_dim': 100,\n",
    "            'embedding_dim': 300,\n",
    "            'dropout': 0.0,\n",
    "            'remove_stopwords': False,\n",
    "            'stem_words': False,\n",
    "            'simple': True,\n",
    "            'log_to_wandb': True,\n",
    "        }\n",
    "        \n",
    "**NOTE: To find the optimal hyperparameters one could implement a grid search for example. \n",
    "\n",
    "##### Metrics \n",
    "There are several metrics that one can use to evaluate a binary classification tasks. I looked at are accuracy, the confusion matrix, F1 score and ROC curve to evaluate the performance of my model. \n",
    "1. Accuracy: The accuracy displays the percentage of of predictions the model gets correct. My model achieves an accuracy between 65 and 78% depending on the hyperparameters used.\n",
    "        \n",
    "2. Confusion Matrix: Sometimes, the accuracy of a classification task alone can be missleading if one has an unequal number of obersevations in each class. The confusion matrix can summaries the overall performance of the classification better by dispalying what is correctly classified, i.e. true positive and true negative, and what is being incorrectly classified, i.e. false positive and false negative [1]. \n",
    "\n",
    "3. F1 Score: The F1-score is often as a binary classification metrics of the model's test accuracy. It is calculated using precision `(TP/(TP + FP))` and recall `(TP/(TP + FN))` [1]. \n",
    "$$F1 = 2*\\frac{precision*recall}{precision + recall}$$\n",
    "If the F1 score is 0, the model performance is poor, i.e. all predicitons are wrong. If the F1 score is 1, all the predictions are correct. The F1-Score of my model consistenly achieves more then 0.7, which is indicating a relatively good model performance.\n",
    "\n",
    "4. ROC Curve: Another common binary classification metric is the ROC-curve (Receiver operating characteristics curve): It displays the performanceof the model at all classification thresholds. It plots the True Positive Rate (TPR) vs the False Positive Rate (FPR). The Area Under the Curve (AUC) metric provides an aggregate measure of performance across all classification thresholds [1]. Advantages of AUC: \n",
    "    - it is scale invariant \n",
    "    - it is classification threshold invariant \n",
    "    \n",
    "Concluding all these metrics can be used to evaluate the performance of a binary classification model. The results of each metric indicates the the implemented Siamese LSTM general performs relatively well on this task. \n",
    "\n",
    "[1] https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkout random sample from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.choice(len(train_dataloader))\n",
    "test_sample_train = dict()\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    if idx == ind:\n",
    "        test_sample_train['q1_text'] = [batch['q1_text'][0]]\n",
    "        test_sample_train['q2_text'] = [batch['q2_text'][0]]\n",
    "        test_sample_train['q1_token'] = [batch['q1_token'][0]]\n",
    "        test_sample_train['q2_token'] = [batch['q2_token'][0]]\n",
    "        test_sample_train['q1_lengths'] = [batch['q1_lengths'][0]]\n",
    "        test_sample_train['q2_lengths'] = [batch['q2_lengths'][0]]\n",
    "        test_sample_train['labels'] = [batch['labels'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question 1: ['what are the names of these plants']\n",
      "question 2: ['what is the name of plant']\n",
      "tokens  q1: [[1, 2, 23, 3465, 37, 205, 6958]]\n",
      "tokens  q2: [[1, 22, 23, 62, 37, 254]]\n",
      "\n",
      "\n",
      "Model predicts 0.0 --> Actual value 0.0\n",
      "Model prediction is correct :)\n",
      "\n",
      "The questions ['what are the names of these plants'] and ['what is the name of plant'] are dissimilar!\n"
     ]
    }
   ],
   "source": [
    "trainer.predict(test_sample_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkout random sample from validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.choice(len(val_dataloader))\n",
    "\n",
    "test_sample_val = dict()\n",
    "for idx, batch in enumerate(val_dataloader):\n",
    "    if idx == ind:\n",
    "        test_sample_val['q1_text'] = [batch['q1_text'][0]]\n",
    "        test_sample_val['q2_text'] = [batch['q2_text'][0]]\n",
    "        test_sample_val['q1_token'] = [batch['q1_token'][0]]\n",
    "        test_sample_val['q2_token'] = [batch['q2_token'][0]]\n",
    "        test_sample_val['q1_lengths'] = [batch['q1_lengths'][0]]\n",
    "        test_sample_val['q2_lengths'] = [batch['q2_lengths'][0]]\n",
    "        test_sample_val['labels'] = [batch['labels'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question 1: ['who is the real pirate king']\n",
      "question 2: ['how do pirates divide the stolen goods']\n",
      "tokens  q1: [[40, 22, 23, 1169, 1832, 1167]]\n",
      "tokens  q2: [[10, 18, 1833, 1834, 23, 1835, 1836]]\n",
      "\n",
      "\n",
      "Model predicts 0.0 --> Actual value 0.0\n",
      "Model prediction is correct :)\n",
      "\n",
      "The questions ['who is the real pirate king'] and ['how do pirates divide the stolen goods'] are dissimilar!\n"
     ]
    }
   ],
   "source": [
    "trainer.predict(test_sample_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict from custom input questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = True  # set to False to create your own inputs\n",
    "similar = False  # select False to dispaly dissimlar example\n",
    "\n",
    "if default:\n",
    "    if similar:\n",
    "        q1 = ['Is it cold today?']\n",
    "        q2 = ['Will it be cold today?']\n",
    "        label = [1.0]\n",
    "    else:\n",
    "        q1 = ['Will I pass the final?']\n",
    "        q2 = ['What will I have for dinner tonight?']\n",
    "        label = [0.0]\n",
    "else:\n",
    "    q1 = input(r'Enter your 1^st question: ')\n",
    "    q2 = input(r'Enter your 2^nd question: ')\n",
    "    label = input('label: ') # 0 for dissimilar, 1 for similar \n",
    "    q1 = [q1]\n",
    "    q2 = [q2]\n",
    "    label = [label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Pairs:  1\n",
      "[('will i pass the final', 'what will i have for dinner tonight')]\n",
      "question 1: ['will i pass the final']\n",
      "question 2: ['what will i have for dinner tonight']\n",
      "tokens  q1: [[41, 12, 1487, 23, 1303]]\n",
      "tokens  q2: [[1, 41, 12, 165, 63, 4425, 11626]]\n",
      "\n",
      "\n",
      "Model predicts 0.0 --> Actual value 0.0\n",
      "Model prediction is correct :)\n",
      "\n",
      "The questions ['will i pass the final'] and ['what will i have for dinner tonight'] are dissimilar!\n"
     ]
    }
   ],
   "source": [
    "# prepair custom input\n",
    "# create df\n",
    "df_own = pd.DataFrame(list(zip(q1, q2, label)), columns=['question1', 'question2', 'is_duplicate'])\n",
    "# prepare data \n",
    "q_pair_own, label = convert_data_to_tuples(df_own, hparams['remove_stopwords'], hparams['stem_words'])\n",
    "print(q_pair_own)\n",
    "\n",
    "# create dataset \n",
    "own_dataset = QuoraDataset(q_pair_own, language.word2index, label)\n",
    "\n",
    "# create dataloader\n",
    "predict_dataloader = torch.utils.data.DataLoader(own_dataset, batch_size=1, collate_fn=collate)\n",
    "\n",
    "for sample in predict_dataloader:\n",
    "    test_sample = sample\n",
    "\n",
    "# predict \n",
    "trainer.predict(test_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback:\n",
    "- I think the task was very interesting and had a good degree of difficulty \n",
    "- One of my first NLP projects so I learned quite a lot, also about concepts I was not to confident with before, like embeddings \n",
    "- I initially struggeled a little bit with the implementation of a Siamese Network, maybe discuss such a specific topic next time also a little bit more in the Intro Sessions, maybe also some theoretical aspects\n",
    "- Clear instructions and well prepared notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission Notes:**\n",
    "\n",
    "1. You can surely use external files to organize your code in classes or modules (e.g. `.py` files). However, please make sure that the notebook can run without errors and all the required files are attached in your submission (e.g. .zip file). If everything is confined in one single notebook, just submit the notebook.\n",
    "2. If you use special libraries or packages, please indicate that clearly and add a `requirements.txt` file to your submission.\n",
    "3. Do not upload the dataset nor submit it in any way.\n",
    "4. Please do not copy code from someone else, the idea here is that you get a chance to write some code in PyTorch and solve the problem on your own. On the other hand, discuss with your colleagues and support them as much as needed. \n",
    "5. You can of course reuse the code in all the notebooks of the course.\n",
    "6. You can also use code and/or ideas from the internet (e.g. Kaggle notebooks), but please always do the following:\n",
    "    - make sure you understand the code so that you can use it correctly\n",
    "    - cite the source in your notebook as markdown or as a comment in the code (`# adopted from .......`) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Criteria:**\n",
    "\n",
    "The most important idea we will use for evaluation is that you should get every component of the complete pipeline (1) doing what it is supposed to do and (2) fitting with the other components.\n",
    "\n",
    "Concrete Examples are:\n",
    "1. Your code runs and we can reproduce the results.\n",
    "2. Dataset: Your code reads the dataset, preprocesses it, splits the text into tokens, etc...\n",
    "3. Dataloading: Your dataset and dataloader produce correct inputs and labels (two questions as input, one binary label).\n",
    "4. Model: Your model takes the input (processes each question correctly) and produces a binary prediction (or score).\n",
    "5. Loss: your chosen loss is suitable for the task (e.g. binary cross entropy in case of the simple classification setup).\n",
    "6. Training: your code for training and validation works without errors and the loss on the training and validation data decreases over the course of training. You do not have to achieve a specific performance.\n",
    "7. Evaluation: you discuss the results and pick correctly some questions from train and validation and show the respective predictions (preferably showing the original question text and not the encoded integer sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus:**\n",
    "If you do any of the following ideas, you get a bonus, additionally you get to learn more, which is better than the bonus:\n",
    "\n",
    "1. Build a baseline model to compare and benchmark your deep learning model against. You can in this case use a classical machine learning model from `scikit-learn`. A starter example is here: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "2. Use W&B or Tensorboard to visualize your training. TensorBoard tutorial is available here: (https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)\n",
    "3. Achieve a relatively good performance on the task.\n",
    "4. Use a learning rate scheduler to improve training. (https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate)\n",
    "5. Use pre-trained embeddings correctly.\n",
    "6. Use an advanced loss suitable for a siamese-network.\n",
    "7. Implement any relevant new idea or discuss an interesting insight about the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
